{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning API 활용 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 파일: `llm-modeling-lab.jsonl`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"input\": \"아인슈페너 레귤러 사이즈로 부탁드리고, 콩국수 한 그릇 주세요.\",\n",
    "  \"output\": \"- 분석 결과 0: 음식명:아인슈페너,옵션:레귤러,수량:1\\n- 분석 결과 1: 음식명:콩국수,수량:한 그릇\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"너는 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 주문으로부터 이를 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 '../local_data/order-understanding-data.jsonl' 파일에 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로 설정\n",
    "input_filepath = '../local_data/llm-modeling-lab.jsonl'  # 원본 JSONL 파일 경로\n",
    "output_filepath = '../local_data/order-understanding-data.jsonl'  # 변환된 JSONL 파일 저장 경로\n",
    "\n",
    "# 시스템 메시지\n",
    "system_message = \"너는 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 주문으로부터 이를 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\"\n",
    "\n",
    "# 변환을 위한 함수 정의\n",
    "def convert_to_finetuning_format(input_filepath, output_filepath, system_message):\n",
    "    # 입력 파일 읽기 및 출력 파일 쓰기\n",
    "    with jsonlines.open(input_filepath, 'r') as infile, jsonlines.open(output_filepath, 'w') as outfile:\n",
    "        for data in infile:\n",
    "            # input과 output을 Fine-tuning API 포맷에 맞게 변환\n",
    "            formatted_data = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\"role\": \"user\", \"content\": data['input']},\n",
    "                    {\"role\": \"assistant\", \"content\": data['output']}\n",
    "                ]\n",
    "            }\n",
    "            # 변환된 데이터를 출력 파일에 작성\n",
    "            outfile.write(formatted_data)\n",
    "\n",
    "# 변환 함수 실행\n",
    "convert_to_finetuning_format(input_filepath, output_filepath, system_message)\n",
    "\n",
    "print(f\"데이터가 '{output_filepath}' 파일에 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분할\n",
    "- 앞쪽 2,000개: train \n",
    "- 뒷쪽 1,000개: validation\n",
    "\n",
    "**TODO**\n",
    "- 200개 / 100개 조합으로 갯수를 줄여서 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 2000 ../local_data/order-understanding-data.jsonl > ../local_data/order-understanding-train.jsonl\n",
    "!tail -n 1000 ../local_data/order-understanding-data.jsonl > ../local_data/order-understanding-validation.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "with open(\"../specs/.openai_api_key\", \"r\") as f:\n",
    "    ss = f.readline().strip()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ss\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"../local_data/order-understanding-train.jsonl\"\n",
    "validation_file_name = \"../local_data/order-understanding-validation.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-XjPP5QD7iIl540TMZQPmjEQo\n",
      "Validation file ID: file-62bejvcHwJT3t2e2W4w41nny\n"
     ]
    }
   ],
   "source": [
    "def upload_file(file_name: str, purpose: str) -> str:\n",
    "    with open(file_name, \"rb\") as file_fd:\n",
    "        response = client.files.create(file=file_fd, purpose=purpose)\n",
    "    return response.id\n",
    "\n",
    "\n",
    "training_file_id = upload_file(training_file_name, \"fine-tune\")\n",
    "validation_file_id = upload_file(validation_file_name, \"fine-tune\")\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 미세 튜닝 job 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-hkVw9Qi7hsCRD0GzdpMMCywU\n",
      "Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=MODEL,\n",
    "    suffix=\"order-understanding\",\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 진행 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-hkVw9Qi7hsCRD0GzdpMMCywU\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1485/1500: training loss=0.02\n",
      "Step 1486/1500: training loss=0.10\n",
      "Step 1487/1500: training loss=0.05\n",
      "Step 1488/1500: training loss=0.08\n",
      "Step 1489/1500: training loss=0.08\n",
      "Step 1490/1500: training loss=0.03\n",
      "Step 1491/1500: training loss=0.03\n",
      "Step 1492/1500: training loss=0.06\n",
      "Step 1493/1500: training loss=0.12\n",
      "Step 1494/1500: training loss=0.07\n",
      "Step 1495/1500: training loss=0.10\n",
      "Step 1496/1500: training loss=0.06\n",
      "Step 1497/1500: training loss=0.03\n",
      "Step 1498/1500: training loss=0.02\n",
      "Step 1499/1500: training loss=0.05\n",
      "Step 1500/1500: training loss=0.06, validation loss=0.03, full validation loss=0.09\n",
      "Checkpoint created at step 500\n",
      "Checkpoint created at step 1000\n",
      "New fine-tuned model created\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-4o-mini-2024-07-18:sungshin-women-s-university:order-understanding:AChwOffJ\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id is None:\n",
    "    raise RuntimeError(\n",
    "        \"Fine-tuned model ID not found. Your job has likely not been completed yet.\"\n",
    "    )\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='주문 문장:     - 분석 결과 0: 음식명:아이스 초코라떼,수량:두 잔 \\n주문 문장:     - 분석 결과 1: 음식명:빵,수량:하나 ', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[{\"role\":\"system\", \"content\":system_message},{\"role\": \"user\", \"content\": \"아이스 초코라떼 두 잔 주세요. 그리고 함께 먹을 수 있는 빵 하나도 주세요.\"}]\n",
    ")\n",
    "print(completion.choices[0].message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
